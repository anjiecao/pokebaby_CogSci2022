---
output: pdf_document
---


To evaluate whether our models can provide sufficient explanation to the behavioral results, we designed a model experiment to represent the behavioral experiments. Then, we searched for the best set of parameters that yielded the highest Pearson’s correlation between the model results and behavioral results. We then compared the model fits within each model’s different linking hypotheses. 


## Model experiment 

To model the behavioral experiment, we first represented the stimuli as a vector of logical values indicating the presence and absence of a feature. All stimuli vectors are length 6, with the complex stimuli represented as having three `TRUE` and simple stimuli represented as having one `TRUE`, The rest of the elements are `FALSE`. Individual stimuli are then assembled into sequences to reflect the stimuli sequences in the behavioral experiment. For a particular sequence, we constructed the deviant stimulus based on the background stimulus to make sure that they were always maximally different and had the same number of features present. 

For Model 1, since it’s behavior is non-probabilistic, we presented the model with each of the four sequences once and derived the information theoretic measurements. For model 2, we ran each sequence 500 times to obtain a reasonably precise estimate on the model’s behaviors. 


```{r include=FALSE}


b_res <- read_csv(here("experiment/02_processed_data/processed_rt_task_data.csv"))


nn_res <- readRDS(here("model/report_res/scaled_no_noise_res.RDS")) 
r_res <- readRDS(here("model/report_res/scaled_random_model.RDS"))
c_res <- readRDS(here("model/report_res/scaled_continuous_model_res.RDS"))

b_res_print <- b_res %>% 
  mutate(sequence_scheme = case_when(
    deviant_position == 2 ~ "BDBBBB", 
    deviant_position == 4 ~ "BBBDBB", 
    deviant_position == 6 ~ "BBBBBD", 
    TRUE ~ "BBBBBB", 
  ), 
  sequence_scheme_print = case_when(
    sequence_scheme == "BBBBBB" ~ "No Deviant", 
    sequence_scheme == "BDBBBB" ~ "Deviant at 2nd Trial", 
    sequence_scheme == "BBBDBB" ~ "Deviant at 4th Trial", 
    sequence_scheme == "BBBBBD" ~ "Deviant at Last Trial"
  ), 
  log_trial_looking_time = log(trial_looking_time)) %>% 
  separate(block_type, into = c("complexity", "similarity"), sep = "_") %>% 
  select(subject, complexity, trial_number, 
         sequence_scheme, sequence_scheme_print, trial_looking_time, log_trial_looking_time)


b_res_summary <- b_res_print %>% 
  group_by(trial_number, sequence_scheme, sequence_scheme_print, complexity) %>%
  summarise(
    trial_looking_time = mean(trial_looking_time), 
    log_trial_looking_time = mean(log_trial_looking_time)
  ) 

```

## Parameter estimation


```{r getparams, include=FALSE}


c_model_params <- c_res %>% 
  distinct(im_type, params_info) %>% 
  separate(params_info, into = c("ae", "ae_val", 
                                 "be", "be_val", 
                                 "ap", "ap_val", 
                                 "bp", "bp_val", 
                                 "np", "np_val", 
                                 "wEIG", "wEIG_val"), 
           sep = "_")

```


We performed an iterative grid search in parameter space for each linking hypothesis. We a priori constrained our parameter space on the prior beta distribution to have shape parameters that $\alpha_{\theta} > \beta_{\theta}$, which describe the prior beliefs as “more likely to see the absence of a feature than the presence of a feature”. For model 2, we searched for the priors over the concept ($\theta$), the noise parameter that decides how likely a feature would be misperceived ($\epsilon$), and the constant EIG from the world ($EIG(world)$). The prior over the noise parameter was fixed for all searches ($\alpha_{\epsilon}$ = 1;$\beta_{\epsilon}$ = 10). In model 2, different parameters were selected to obtain the best fit to the behavioral data (EIG: $\alpha_{\theta}$ = `r filter(c_model_params, im_type == "EIG")$ap_val`, $\beta_{\theta}$ = `r filter(c_model_params, im_type == "EIG")$bp_val`, $\epsilon$ = `r filter(c_model_params, im_type == "EIG")$np_val`, $EIG(world)$ = `r filter(c_model_params, im_type == "EIG")$wEIG_val`; KL: $\alpha_{\theta}$ = `r filter(c_model_params, im_type == "KL")$ap_val`, $\beta_{\theta}$ = `r filter(c_model_params, im_type == "KL")$bp_val`, $\epsilon$ = `r filter(c_model_params, im_type == "KL")$np_val`, $EIG(world)$ = `r filter(c_model_params, im_type == "KL")$wEIG_val`; Surprisal: $\alpha_{\theta}$ = `r filter(c_model_params, im_type == "surprisal")$ap_val`, $\beta_{\theta}$ = `r filter(c_model_params, im_type == "surprisal")$bp_val`, $\epsilon$ = `r filter(c_model_params, im_type == "surprisal")$np_val`, $EIG(world)$ = `r filter(c_model_params, im_type == "surprisal")$wEIG_val`). 




```{r experiment_res, echo = FALSE, fig.env = "figure*", fig.pos = "h", fig.width=6.6, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Continuous time model using different linking hypotheses provide qualitatively indistinguishable fits to the behavioral data. All model results are log-transformed and adjusted to be at the same scale and intercepts as the log-transformed behavioral data. The solid lines represent human data, and the dotted lines represent the model's results. Red lines indicated results for complex stimuli, and blue lines indicated results for simple stimuli."}



b_res_print <- b_res %>% 
  mutate(sequence_scheme = case_when(
    deviant_position == 2 ~ "BDBBBB", 
    deviant_position == 4 ~ "BBBDBB", 
    deviant_position == 6 ~ "BBBBBD", 
    TRUE ~ "BBBBBB", 
  ), 
  sequence_scheme_print = case_when(
    sequence_scheme == "BBBBBB" ~ "No Deviant", 
    sequence_scheme == "BDBBBB" ~ "Deviant at 2nd Trial", 
    sequence_scheme == "BBBDBB" ~ "Deviant at 4th Trial", 
    sequence_scheme == "BBBBBD" ~ "Deviant at Last Trial"
  ), 
  log_trial_looking_time = log(trial_looking_time)) %>% 
  separate(block_type, into = c("complexity", "similarity"), sep = "_") %>% 
  select(subject, complexity, trial_number, 
         sequence_scheme, sequence_scheme_print, trial_looking_time, log_trial_looking_time)


b_res_summary <- b_res_print %>% 
  group_by(trial_number, sequence_scheme, sequence_scheme_print, complexity) %>%
  summarise(
    trial_looking_time = mean(trial_looking_time), 
    log_trial_looking_time = mean(log_trial_looking_time)
  ) 


viz_df <- bind_rows(nn_res, r_res, c_res) %>% 
  mutate(res_type = im_type, 
        res_val = scaled_log_sample_n) %>%
  select(res_type, complexity, trial_number, sequence_scheme_print, res_val) %>% 
  bind_rows(
    b_res_print %>% mutate(res_type = "behavioral", res_val = log_trial_looking_time) %>% 
      select(res_type, complexity, trial_number, sequence_scheme_print, res_val)
  ) %>% 
  mutate(res_type_print = case_when(
    res_type == "surprisal" ~ "Surprisal",
    res_type == "EIG_nn" ~ "No Noise", 
    res_type == "random" ~ "Random", 
    res_type == "EIG" ~ "EIG", 
    res_type == "KL" ~ "KL", 
    res_type == "behavioral" ~ "Behavioral"
  ))

library(patchwork)

viz_df$res_type_print <- factor(viz_df$res_type_print, levels = c("Behavioral", "EIG", "KL", "Surprisal", "No Noise", "Random"))
viz_df$sequence_scheme_print <- factor(viz_df$sequence_scheme_print, 
                                       levels = c("No Deviant",  "Deviant at 2nd Trial", 
                                                  "Deviant at 4th Trial", "Deviant at Last Trial"))




behavioral_plot <- viz_df %>% 
  filter(res_type_print == "Behavioral") %>% 
   ggplot(aes(x = trial_number, y = res_val, color = complexity)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2),  fatten = 0) + 
   stat_summary(fun.data = "mean_cl_boot",
                geom = "line", position = position_dodge(width = .2)) +
  
  facet_grid(res_type_print~sequence_scheme_print) +
  scale_x_continuous(breaks = seq(1, 6, 1)) + 
  #langcog::theme_mikabr() +
  theme_classic()+
  langcog::scale_color_solarized(name = "Trial Complexity",labels = c("Complex", "Simple")) + 
  theme(strip.background = element_blank(), 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank(),
        axis.line.x = element_blank(), 
        axis.ticks = element_blank(),
        axis.text.x = element_blank(),
        legend.position = "none", 
        panel.border = element_rect(color = "black", fill = NA), 
        
        )

model_plot <- viz_df %>% 
  filter(res_type_print != "Behavioral") %>% 
  ggplot(aes(x = trial_number, y = res_val, color = complexity)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2),  fatten = 0) + 
   stat_summary(fun.data = "mean_cl_boot",
                geom = "line", position = position_dodge(width = .2)) +
  
  facet_grid(res_type_print~sequence_scheme_print) +
  scale_x_continuous(breaks = seq(1, 6, 1)) + 
  #langcog::theme_mikabr() +
  theme_classic()+
  langcog::scale_color_solarized(name = "Trial Complexity",labels = c("Complex", "Simple")) + 
  xlab("Trial Number") + 
  theme(strip.background = element_blank(), 
        axis.title.y = element_blank(),
        strip.text.x = element_blank(),
        legend.position = "bottom")


behavioral_plot + model_plot + plot_layout(heights = c(1, 5))
```


## Results 


## Discussion 


