---
output:   
  bookdown::pdf_document2

---

```{r include = FALSE}
# loading data 
all_d <- read_csv(here("experiment/01_merged_data/merged_data.csv"))
d <- read_csv(here("experiment/02_processed_data/processed_rt_task_data.csv"))
prolific <- read_csv(here("experiment/prolific.csv"))
exclusion_d <- read_csv(here("experiment/p_level_exclusion.csv"))


b_res_print <- d %>% 
  mutate(sequence_scheme = case_when(
    deviant_position == 2 ~ "BDBBBB", 
    deviant_position == 4 ~ "BBBDBB", 
    deviant_position == 6 ~ "BBBBBD", 
    TRUE ~ "BBBBBB", 
  ), 
  sequence_scheme_print = case_when(
    sequence_scheme == "BBBBBB" ~ "No Deviant", 
    sequence_scheme == "BDBBBB" ~ "Deviant at 2nd Trial", 
    sequence_scheme == "BBBDBB" ~ "Deviant at 4th Trial", 
    sequence_scheme == "BBBBBD" ~ "Deviant at Last Trial"
  ), 
  log_trial_looking_time = log(trial_looking_time)) %>% 
  separate(block_type, into = c("complexity", "similarity"), sep = "_") %>% 
  select(subject, complexity, trial_number, 
         sequence_scheme, sequence_scheme_print, trial_looking_time, log_trial_looking_time)

# calculate smean.cl.b


b_res_summary <- b_res_print %>% 
  group_by(trial_number, sequence_scheme, sequence_scheme_print, complexity) %>%
  summarise(
    trial_looking_time = mean(trial_looking_time), 
    log_trial_looking_time = mean(log_trial_looking_time)
  ) 

```



## Methods 

### Participants



```{r message=FALSE, warning=FALSE, include=FALSE}
## total participants 
total_participants <- length(unique(all_d$subject))


## age 
all_age <- all_d %>% select(subject, responses) %>% 
  filter(grepl("age", responses)) %>% 
  mutate(responses = map(responses, ~ jsonlite::fromJSON(.))) %>% 
  unnest(cols = responses) %>% unnest( cols = responses) %>% 
  mutate(age = as.numeric(gsub("\\D+","",responses))) %>% 
  filter(!is.na(age)) %>% 
  pull(age)
age_mean <- round(mean(all_age), 2)
age_sd <- round(sd(all_age), 2)

## conditions before exclusion 
all_conditions <- all_d %>% 
  filter(stimulus_type %in% c("curiousity", "memory_test", "math_question")) %>% 
  distinct(subject, stimulus_type) %>% 
  group_by(stimulus_type) %>% 
  summarise(n = n())

## participants excluded for irregular reaction time 
exclude_n <- length(unique(exclusion_d$sbj))

## final included participants 
sample_n <- d %>% 
  distinct(subject, task_type) %>% 
  group_by(task_type) %>% 
  summarise(n = n())
```



We recruited `r total_participants` participants (Age *M* = `r age_mean`; *SD* = `r age_sd`) on Prolific. They were randomly assigned to one of the three conditions of the experiment (Curiosity: *N* = `r filter(all_conditions, stimulus_type == "curiousity")$n`; Memory: *N* = `r filter(all_conditions, stimulus_type == "memory_test")$n`; Math: *N* = `r filter(all_conditions, stimulus_type == "math_question")$n`). Participants were excluded if they showed irregular reaction times or their responses in the filler tasks indicates low engagement with the experiment. All exclusion criteria were pre-registered. The final sample included N participants (Curiosity *N* = `r filter(sample_n, task_type == "curiosity")$n`; Memory: *N* = `r filter(sample_n, task_type == "memory")$n`; Math: N = *N* = `r filter(sample_n, task_type == "math")$n`).


### Procedure

This is a web-based self-paced visual presentation task. Participants were instructed to look at a sequence of animated creatures at their own pace and answer some questions throughout. At the end of the experiment, participants were asked to rate the similarity between pairs of creatures and complexity of creatures they encountered on a 7-point Likert Scale. Each participant saw eight blocks in total, half of which used creatures with high perceptual complexity, and half of which used creatures with low perceptual complexity. On each trial, an animated creature showed up on the screen. participants can press the down arrow to go to the next trial whenever they want after a minimum viewing time of 500 ms.

Each block consisted of six trials. A trial can be either a background trial (B) or a deviant trial (D). A background trial presented a creature repeatedly, and the deviant trial presented a different creature from the background trial in the block. Two creatures in the blocks were matched for visual complexity. There were four sequences of background trials and deviant trials. Each sequence appeared twice, once with high complexity stimuli and once with low complexity stimuli. The deviant trial can appear at either the second (BDBBBB), the fourth (BBBDBB), or the sixth trial (BBBBBD) in the block. Two blocks do not have deviant trials (BBBBBB). The creatures presented in the deviant trials and background trials were matched for complexity. An overview of the experimental design can be seen in Figure \@ref(fig:experimental_design).

```{r experimental_design, echo = FALSE, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "Experimental design and examples of simple and complex stimuli. In each block, a deviant could appear on the second, fourth (as depicted here) or sixth trial or not at all. Stimuli within a block were either all simple or all complex."}
img <- png::readPNG("figs/experimental_design.png")
grid::grid.raster(img)
cat("{#fig:experimental_design}")
```

Participants were randomly assigned to one of the three conditions: Curiosity, Memory, and Math The three conditions only differed in the type of questions asked following each block. In Curiosity condition, participants were asked to rate "How curious are you about the creature?" on a 5-point Likert scale. In Memory condition, a forced-choice recognition question followed each block ("Have you seen this creature before?"). The creature used in the question in both conditions was either a creature presented in the preceding block or a novel creature matched in complexity. In Math condition,  the participants were asked a simple arithmetic question ("What is 5 + 7?") in multiple-choice format. 


### Stimuli 

```{r behavioral_result, echo = FALSE, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.5, fig.height=3.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Results of behavioral experiment."}

b_res_print %>% 
  ggplot(aes(x=trial_number, y=log(trial_looking_time), color = complexity)) + 
   stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
   stat_summary(fun.data = "mean_cl_boot", geom = "line", position = position_dodge(width = .2))+
  #geom_smooth(method = "lm", 
  #            formula = y ~ I(exp(1)**(-x)), se = FALSE) + 
  facet_wrap(~sequence_scheme_print) +
  scale_x_continuous(breaks = seq(1, 6, 1)) + 
  #langcog::theme_mikabr() +
  theme_classic()+
  langcog::scale_color_solarized(name = "Trial Complexity",labels = c("Complex", "Simple")) + 
  theme(legend.position = "bottom") + 
  ylab("log Looking time (ms)") + 
  xlab("Trial Number") + 
  theme(axis.title = element_text(size = 8.5),
        legend.title = element_text(size = 8.5),
        legend.text = element_text(size = 8.5))
```


The animated creatures (Fig 1) were created using Spore (a game developed by Maxis in 2008). There were forty creatures in total, half of which have low perceptual complexity (e.g. the creatures do not have limbs, additional body parts, facial features, or textured skin), and half of which have high perceptual complexity (i.e. they do have the aforementioned features). We used the "animated avatar" function in Spore to capture the creatures in motion.


## Results 



### Analytic Approach 

The sample size, methods, and main analyses were all pre-registered and are available at [LINK]. Data and analysis scripts are available at [LINK]. 


### Manipulation Check 

 The complex animated creatures were rated as more perceptually complex (M = ; SD = ) than the simple animated creatures (M = ; SD = ). Pairs of background creature and deviant creature were rated as moderately dissimilar to one another (M = ; SD = ). 


### Evaluating the Paradigm 


```{r include=FALSE}
#preregistration: log(looking time) ~ I((exp(1)**(-trial_number))) * item_type * trial_complexity + (trial_number * item_type * trial_complexity|subject)

# didn't converge 
#model_0 <- lme4::lmer(log(trial_looking_time) ~ I(exp(1)**(-trial_number)) * trial_type * block_type + (trial_number * trial_type * block_type | subject),data = d)

model_1 <- lmerTest::lmer(log(trial_looking_time) ~ I(exp(1)**(-trial_number)) * trial_type * block_type + (1 | subject), data = d)
summary(model_1)

```


Three criteria were selected to evaluate whether the paradigms successfully captured the characteristic looking time patterns observed in infant literature: habituation (the decrease in looking time for a stimulus with repeated presentations), dishabituation (the increase in looking time to a new stimulus after habituated to one stimulus), and complexity effect (longer looking time for perceptually more complex stimuli). To evaluate the phenomenon quantitatively, we ran a linear mixed effects model with maximal random effect structure. [DESCRIBE THE MODEL]. [REPORT THE MODEL RESULTS]


## Discussion 